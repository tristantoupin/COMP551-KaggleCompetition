{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CNN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "sDGhFDtdP_0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn import svm, metrics\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import random\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from scipy import stats\n",
        "import math\n",
        "from skimage import morphology, img_as_bool"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nt0OtpF6WXXa",
        "colab_type": "code",
        "outputId": "ce2b5a43-e585-4288-b7e8-7550d5f5520e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MuK3fO6SP_0Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_to_data = \"gdrive/My Drive/data/train_images.npy\"\n",
        "path_to_labels = \"gdrive/My Drive/data/train_labels.csv\"\n",
        "path_to_test = \"gdrive/My Drive/data/test_images.npy\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uA-4nzfSP_0X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_images(list_of_images, max_col = 4):\n",
        "    n = len(list_of_images)\n",
        "    if n == 1:\n",
        "        plt.imshow(list_of_images[0], cmap=\"gray\"); plt.axis('off'); plt.show()\n",
        "    else:\n",
        "        # get number of columns and rows required\n",
        "        r, c = 1, n\n",
        "        if n > max_col:\n",
        "            c = max_col\n",
        "            r = int(math.ceil(n/max_col))\n",
        "    \n",
        "        fig = plt.figure(figsize=(20, max_col * r))\n",
        "        for i, (img,name) in enumerate(list_of_images):\n",
        "            ax = fig.add_subplot(r, c, (i+1))\n",
        "            ax.set_title(str(name))\n",
        "            ax.axis('off')\n",
        "            ax.imshow(img, cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TZRn5lD6P_0Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data(path_x, path_y):\n",
        "    data = np.load(path_x, encoding = 'bytes')\n",
        "    labels_df = pd.read_csv(path_y)\n",
        "    labels_df.Category = pd.Categorical(labels_df.Category)\n",
        "    y = labels_df.Category.cat.codes.values\n",
        "    X = np.array(data[:, 1])\n",
        "    for c, i in enumerate(X):\n",
        "        ret,thresh_img = cv2.threshold(i,127,255,cv2.THRESH_BINARY)\n",
        "        X[c] = thresh_img\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VqFde78xP_0d",
        "colab_type": "code",
        "outputId": "9d563b26-3cf1-4e2a-f9c9-4b52c9612121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "X_noisy, y = get_data(path_to_data, path_to_labels)\n",
        "print(\"Shape of training dataset:\", len(X_noisy))\n",
        "X_test = list(np.load(path_to_test, encoding = 'bytes')[:, 1])\n",
        "print(\"Shape of testing dataset:\", len(X_test))\n",
        "unique_classes = set(y)\n",
        "print(\"Number of classes:\", len(unique_classes))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training dataset: 10000\n",
            "Shape of testing dataset: 10000\n",
            "Number of classes: 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RXrUpdFhP_0q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy import ndimage\n",
        "\n",
        "def remove_noise(filledImg, min_size = 500):\n",
        "    blobs, min_val = ndimage.label(filledImg)\n",
        "    \n",
        "    for i in range(10,60):\n",
        "        clean_img = morphology.remove_small_objects(img_as_bool(filledImg), i)\n",
        "        blobs, number_of_blobs = ndimage.label(clean_img)\n",
        "        if number_of_blobs < min_val:\n",
        "            min_val = number_of_blobs\n",
        "            if min_val == 1:\n",
        "                return clean_img\n",
        "    return clean_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TqY99QqOP_1a",
        "colab_type": "code",
        "outputId": "cd1b2438-711b-49fc-8660-1930f1c93331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "X = []\n",
        "for c, img in enumerate(X_noisy):\n",
        "    img = img.reshape(100, 100)\n",
        "    X.append(remove_noise(img, 100).flatten())\n",
        "  "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/util/dtype.py:118: UserWarning: Possible sign loss when converting negative image of type float64 to positive image of type bool.\n",
            "  .format(dtypeobj_in, dtypeobj_out))\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to bool\n",
            "  .format(dtypeobj_in, dtypeobj_out))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0eXGh_j9P_1g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for c, img in enumerate(X):\n",
        "    X[c] = np.array(img)\n",
        "X = np.array(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "64EcjwRFP_1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3b98720f-451d-4992-be29-ad88d88692cd"
      },
      "cell_type": "code",
      "source": [
        "def crop_image(array_X, size_of_image = 100, size_of_crop = 32, show_image = False):\n",
        "  cropped = []\n",
        "  cropBox = None\n",
        "  for i in range(len(array_X)):\n",
        "    test = array_X[i]\n",
        "    test.resize(size_of_image,size_of_image)\n",
        "    image_data = test\n",
        "    if cropBox == None:\n",
        "      prev_cropBox = None\n",
        "    else:\n",
        "      prev_cropBox = cropBox[:]\n",
        "\n",
        "    try:  \n",
        "      non_empty_columns = np.where(image_data.max(axis=0)>0)[0]\n",
        "      non_empty_rows = np.where(image_data.max(axis=1)>0)[0]\n",
        "      cropBox = (min(non_empty_rows), max(non_empty_rows), min(non_empty_columns), max(non_empty_columns))\n",
        "    except:\n",
        "      cropBox = prev_cropBox\n",
        "    shiftX = size_of_crop\n",
        "    shiftY = size_of_crop\n",
        "    cropBox = list(cropBox)\n",
        "    if(cropBox[0] >= 5):\n",
        "      cropBox[0] -= 5\n",
        "\n",
        "    if(cropBox[0]+shiftX >= size_of_image):\n",
        "      cropBox[0] = size_of_image - shiftX - 1\n",
        "\n",
        "    if(cropBox[2] >= 5):\n",
        "      cropBox[2] -= 5\n",
        "\n",
        "    if(cropBox[2]+shiftY >= size_of_image):\n",
        "      cropBox[2] = size_of_image - shiftY - 1\n",
        "\n",
        "    image_data_new = image_data[cropBox[0]:cropBox[0]+shiftX, cropBox[2]:cropBox[2]+shiftY]\n",
        "    \n",
        "    if show_image:\n",
        "      plot_images(np.array([image_data_new]))\n",
        "\n",
        "    cropped.append(image_data_new.flatten())\n",
        "  \n",
        "  for c, img in enumerate(cropped):\n",
        "    cropped[c] = np.array(img)\n",
        "  cropped = np.array(cropped)\n",
        "  return cropped"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "o8G62U9lP_11",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_cropped = crop_image(X, size_of_crop=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h4xkhRKcku6J",
        "colab_type": "code",
        "outputId": "3fc110f2-55b9-4358-ba50-1fa387a1d451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1836
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 31\n",
        "epochs = 50\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 32, 32\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = (X_cropped[:7000],y[:7000]), (X_cropped[7000:],y[7000:]) \n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_train[3])\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "datagen.fit(x_train)\n",
        "val_datagen = ImageDataGenerator()\n",
        "val_datagen.fit(x_test)\n",
        "train_generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
        "validation_generator = val_datagen.flow(x_test, y_test, batch_size=batch_size)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(lr=0.002,\n",
        "                  beta_1=0.9,\n",
        "                  beta_2=0.999,\n",
        "                  epsilon=1e-08,\n",
        "                  schedule_decay=0.004)\n",
        "\n",
        "# Set our optimizer and loss function (similar settings to our CAE approach)\n",
        "model.compile(loss = keras.losses.categorical_crossentropy,\n",
        "            optimizer = optimizer,\n",
        "            metrics = ['categorical_accuracy'])\n",
        "\n",
        "model.fit_generator(train_generator,\n",
        "          steps_per_epoch= 14000 // batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1)\n",
        "\n",
        "# model.fit(x_train, y_train,\n",
        "#           batch_size= batch_size,\n",
        "#           epochs=epochs,\n",
        "#           verbose=1,\n",
        "#          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (7000, 32, 32, 1)\n",
            "7000 train samples\n",
            "3000 test samples\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/50\n",
            "437/437 [==============================] - 13s 29ms/step - loss: 2.7785 - categorical_accuracy: 0.1992\n",
            "Epoch 2/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 2.2449 - categorical_accuracy: 0.3501\n",
            "Epoch 3/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.9841 - categorical_accuracy: 0.4236\n",
            "Epoch 4/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.8478 - categorical_accuracy: 0.4629\n",
            "Epoch 5/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.7455 - categorical_accuracy: 0.4935\n",
            "Epoch 6/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.6687 - categorical_accuracy: 0.5101\n",
            "Epoch 7/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.6019 - categorical_accuracy: 0.5345\n",
            "Epoch 8/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.5665 - categorical_accuracy: 0.5458\n",
            "Epoch 9/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.5127 - categorical_accuracy: 0.5579\n",
            "Epoch 10/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.4968 - categorical_accuracy: 0.5576\n",
            "Epoch 11/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.4482 - categorical_accuracy: 0.5759\n",
            "Epoch 12/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.4169 - categorical_accuracy: 0.5871\n",
            "Epoch 13/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.4114 - categorical_accuracy: 0.5842\n",
            "Epoch 14/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.3835 - categorical_accuracy: 0.5953\n",
            "Epoch 15/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.3616 - categorical_accuracy: 0.5985\n",
            "Epoch 16/50\n",
            "437/437 [==============================] - 11s 24ms/step - loss: 1.3400 - categorical_accuracy: 0.6044\n",
            "Epoch 17/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.3374 - categorical_accuracy: 0.6071\n",
            "Epoch 18/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.3278 - categorical_accuracy: 0.6060\n",
            "Epoch 19/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.3081 - categorical_accuracy: 0.6108\n",
            "Epoch 20/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2911 - categorical_accuracy: 0.6170\n",
            "Epoch 21/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2846 - categorical_accuracy: 0.6193\n",
            "Epoch 22/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2812 - categorical_accuracy: 0.6182\n",
            "Epoch 23/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2619 - categorical_accuracy: 0.6209\n",
            "Epoch 24/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2658 - categorical_accuracy: 0.6276\n",
            "Epoch 25/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2410 - categorical_accuracy: 0.6292\n",
            "Epoch 26/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2380 - categorical_accuracy: 0.6322\n",
            "Epoch 27/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2327 - categorical_accuracy: 0.6349\n",
            "Epoch 28/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2259 - categorical_accuracy: 0.6396\n",
            "Epoch 29/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2271 - categorical_accuracy: 0.6344\n",
            "Epoch 30/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2110 - categorical_accuracy: 0.6366\n",
            "Epoch 31/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2002 - categorical_accuracy: 0.6420\n",
            "Epoch 32/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.1941 - categorical_accuracy: 0.6451\n",
            "Epoch 33/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.1883 - categorical_accuracy: 0.6421\n",
            "Epoch 34/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.1939 - categorical_accuracy: 0.6416\n",
            "Epoch 35/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2010 - categorical_accuracy: 0.6439\n",
            "Epoch 36/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.1716 - categorical_accuracy: 0.6493\n",
            "Epoch 37/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.1736 - categorical_accuracy: 0.6474\n",
            "Epoch 38/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.1620 - categorical_accuracy: 0.6560\n",
            "Epoch 39/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.1653 - categorical_accuracy: 0.6558\n",
            "Epoch 40/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.1668 - categorical_accuracy: 0.6496\n",
            "Epoch 41/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.1646 - categorical_accuracy: 0.6539\n",
            "Epoch 42/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.2153 - categorical_accuracy: 0.6363\n",
            "Epoch 43/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.1692 - categorical_accuracy: 0.6521\n",
            "Epoch 44/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.1372 - categorical_accuracy: 0.6573\n",
            "Epoch 45/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.1389 - categorical_accuracy: 0.6574\n",
            "Epoch 46/50\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 1.1248 - categorical_accuracy: 0.6629\n",
            "Epoch 47/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.1450 - categorical_accuracy: 0.6560\n",
            "Epoch 48/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.1351 - categorical_accuracy: 0.6625\n",
            "Epoch 49/50\n",
            "437/437 [==============================] - 11s 24ms/step - loss: 1.1451 - categorical_accuracy: 0.6617\n",
            "Epoch 50/50\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 1.1158 - categorical_accuracy: 0.6680\n",
            "Test loss: 1.5782222073872885\n",
            "Test accuracy: 0.6453333334922791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6jW2SJXAu0Um",
        "colab_type": "code",
        "outputId": "62e9dc9c-fbf3-46d4-f902-a202e76080d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "test = []\n",
        "for c, img in enumerate(X_test):\n",
        "    img = img.reshape(100, 100)\n",
        "    test.append(remove_noise(img, 100).flatten())\n",
        "    \n",
        "for c, img in enumerate(test):\n",
        "    test[c] = np.array(img)\n",
        "test = np.array(test)\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/util/dtype.py:118: UserWarning: Possible sign loss when converting negative image of type float64 to positive image of type bool.\n",
            "  .format(dtypeobj_in, dtypeobj_out))\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to bool\n",
            "  .format(dtypeobj_in, dtypeobj_out))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "hW-CTFsrLpaQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_cropped = crop_image(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtCICMzUKlQY",
        "colab_type": "code",
        "outputId": "18983ed4-8979-4c4b-ff25-e5f87f75d71e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_x = test_cropped\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    test_x = test_x.reshape(test_x.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    test_x = test_x.reshape(test_x.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "test_x = test_x.astype('float32')\n",
        "\n",
        "prediction = model.predict_classes(test_x, batch_size=1, verbose=1)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 25s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4gMQ7BlsMl59",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "result = []\n",
        "labels_df = pd.read_csv(path_to_labels)\n",
        "labels_df.Category = pd.Categorical(labels_df.Category)\n",
        "cat_map = pd.Categorical(labels_df.Category)\n",
        "cat_map = cat_map.categories\n",
        "for index, image in enumerate(prediction):\n",
        "  result.append(cat_map[image])\n",
        "  \n",
        "result = pd.DataFrame(result)\n",
        "result = result.reset_index(drop=False)\n",
        "result.columns=['Id', 'Category']\n",
        "result.to_csv('result.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i5lRNhqfNTha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ONxnOMQXVy7V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}