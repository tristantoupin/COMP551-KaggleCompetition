{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, metrics\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../data/train_images.npy\"\n",
    "path_to_labels = \"../data/train_labels.csv\"\n",
    "path_to_test = \"../data/test_images.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/train_images.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-99cfa9829267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabels_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/train_images.npy'"
     ]
    }
   ],
   "source": [
    "data = np.load(path_to_data, encoding = 'bytes')\n",
    "labels_df = pd.read_csv(path_to_labels)\n",
    "labels_df.Category = pd.Categorical(labels_df.Category)\n",
    "y = labels_df.Category.cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(list_of_images, max_col = 4):\n",
    "    n = len(list_of_images)\n",
    "    if n == 1:\n",
    "        plt.imshow(list_of_images[0], cmap = 'gray_r'); plt.axis('off'); plt.show()\n",
    "    else:\n",
    "        # get number of columns and rows required\n",
    "        r, c = 1, n\n",
    "        if n > max_col:\n",
    "            c = max_col\n",
    "            r = int(math.ceil(n/max_col))\n",
    "    \n",
    "        fig = plt.figure(figsize=(17, max_col * r))\n",
    "        for i, (img,name) in enumerate(list_of_images):\n",
    "            ax = fig.add_subplot(r, c, (i+1))\n",
    "            ax.set_title(str(name))\n",
    "            ax.axis('off')\n",
    "            ax.imshow(img, cmap = 'gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-65d62002c4d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "X = list(data[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5d8b975a870c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "x_tr, x_val, y_tr, y_val = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = np.array([x.reshape(100, 100) for x in x_tr])\n",
    "x_val = np.array([x.reshape(100, 100) for x in x_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 100, 100)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_random_clf(x_tr, y_tr, x_test, y_test, r = 1234):\n",
    "    clf = DummyClassifier(strategy = 'uniform', random_state = r)\n",
    "    clf.fit(x_tr, y_tr)\n",
    "    preds = clf.predict(x_test)\n",
    "    metric = metrics.classification_report(y_test, preds)\n",
    "    return metric\n",
    "    \n",
    "def performance_majority_classifier(x_tr, y_tr, x_test, y_test, r = 1234):\n",
    "    most_common_val = stats.mode(y_tr).mode[0]\n",
    "    preds = np.full((y_test.shape), most_common_val)\n",
    "    metric = metrics.classification_report(y_test, preds)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.03      0.03       110\n",
      "           1       0.04      0.04      0.04       108\n",
      "           2       0.06      0.04      0.04       168\n",
      "           3       0.08      0.04      0.05       204\n",
      "           4       0.07      0.05      0.06       142\n",
      "           5       0.04      0.03      0.03       139\n",
      "           6       0.00      0.00      0.00        56\n",
      "           7       0.03      0.02      0.02       158\n",
      "           8       0.04      0.04      0.04        95\n",
      "           9       0.02      0.03      0.02        68\n",
      "          10       0.03      0.05      0.04        62\n",
      "          11       0.02      0.03      0.02        63\n",
      "          12       0.04      0.08      0.05        51\n",
      "          13       0.05      0.06      0.05        89\n",
      "          14       0.04      0.04      0.04       102\n",
      "          15       0.02      0.03      0.03        93\n",
      "          16       0.05      0.04      0.05       142\n",
      "          17       0.05      0.04      0.04       154\n",
      "          18       0.01      0.01      0.01       124\n",
      "          19       0.01      0.01      0.01        75\n",
      "          20       0.01      0.01      0.01       149\n",
      "          21       0.03      0.04      0.03        84\n",
      "          22       0.03      0.02      0.02       152\n",
      "          23       0.01      0.01      0.01       120\n",
      "          24       0.01      0.02      0.01        63\n",
      "          25       0.02      0.02      0.02        92\n",
      "          26       0.01      0.01      0.01       101\n",
      "          27       0.07      0.05      0.06       136\n",
      "          28       0.02      0.02      0.02        94\n",
      "          29       0.01      0.02      0.01        52\n",
      "          30       0.01      0.02      0.01        54\n",
      "\n",
      "   micro avg       0.03      0.03      0.03      3300\n",
      "   macro avg       0.03      0.03      0.03      3300\n",
      "weighted avg       0.03      0.03      0.03      3300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       110\n",
      "           1       0.00      0.00      0.00       108\n",
      "           2       0.00      0.00      0.00       168\n",
      "           3       0.06      1.00      0.12       204\n",
      "           4       0.00      0.00      0.00       142\n",
      "           5       0.00      0.00      0.00       139\n",
      "           6       0.00      0.00      0.00        56\n",
      "           7       0.00      0.00      0.00       158\n",
      "           8       0.00      0.00      0.00        95\n",
      "           9       0.00      0.00      0.00        68\n",
      "          10       0.00      0.00      0.00        62\n",
      "          11       0.00      0.00      0.00        63\n",
      "          12       0.00      0.00      0.00        51\n",
      "          13       0.00      0.00      0.00        89\n",
      "          14       0.00      0.00      0.00       102\n",
      "          15       0.00      0.00      0.00        93\n",
      "          16       0.00      0.00      0.00       142\n",
      "          17       0.00      0.00      0.00       154\n",
      "          18       0.00      0.00      0.00       124\n",
      "          19       0.00      0.00      0.00        75\n",
      "          20       0.00      0.00      0.00       149\n",
      "          21       0.00      0.00      0.00        84\n",
      "          22       0.00      0.00      0.00       152\n",
      "          23       0.00      0.00      0.00       120\n",
      "          24       0.00      0.00      0.00        63\n",
      "          25       0.00      0.00      0.00        92\n",
      "          26       0.00      0.00      0.00       101\n",
      "          27       0.00      0.00      0.00       136\n",
      "          28       0.00      0.00      0.00        94\n",
      "          29       0.00      0.00      0.00        52\n",
      "          30       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.06      0.06      0.06      3300\n",
      "   macro avg       0.00      0.03      0.00      3300\n",
      "weighted avg       0.00      0.06      0.01      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(performance_random_clf(x_tr, y_tr, x_val, y_val))\n",
    "print(performance_majority_classifier(x_tr, y_tr, x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "lSVM_cs = [1,10000]\n",
    "n_fine_tune = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "def linear_SVM(x_tr, y_tr, x_val, y_val):\n",
    "    f1_scores = []\n",
    "    model = svm.SVC()\n",
    "    model.fit(x_tr, y_tr)\n",
    "    preds = model.predict(x_val)\n",
    "    metric = metrics.classification_report(y_val, preds)\n",
    "\n",
    "    return model, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "a, b = linear_SVM(x_tr, y_tr, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       110\n",
      "           1       0.00      0.00      0.00       108\n",
      "           2       0.00      0.00      0.00       168\n",
      "           3       0.06      1.00      0.12       204\n",
      "           4       0.00      0.00      0.00       142\n",
      "           5       0.00      0.00      0.00       139\n",
      "           6       0.00      0.00      0.00        56\n",
      "           7       0.00      0.00      0.00       158\n",
      "           8       0.00      0.00      0.00        95\n",
      "           9       0.00      0.00      0.00        68\n",
      "          10       0.00      0.00      0.00        62\n",
      "          11       0.00      0.00      0.00        63\n",
      "          12       0.00      0.00      0.00        51\n",
      "          13       0.00      0.00      0.00        89\n",
      "          14       0.00      0.00      0.00       102\n",
      "          15       0.00      0.00      0.00        93\n",
      "          16       0.00      0.00      0.00       142\n",
      "          17       0.00      0.00      0.00       154\n",
      "          18       0.00      0.00      0.00       124\n",
      "          19       0.00      0.00      0.00        75\n",
      "          20       0.00      0.00      0.00       149\n",
      "          21       0.00      0.00      0.00        84\n",
      "          22       0.00      0.00      0.00       152\n",
      "          23       0.00      0.00      0.00       120\n",
      "          24       0.00      0.00      0.00        63\n",
      "          25       0.00      0.00      0.00        92\n",
      "          26       0.00      0.00      0.00       101\n",
      "          27       0.00      0.00      0.00       136\n",
      "          28       0.00      0.00      0.00        94\n",
      "          29       0.00      0.00      0.00        52\n",
      "          30       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.06      0.06      0.06      3300\n",
      "   macro avg       0.00      0.03      0.00      3300\n",
      "weighted avg       0.00      0.06      0.01      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "def fine_tune_SVM(x_tr, y_tr, x_val, y_val,\n",
    "                         number_of_model, cs):\n",
    "    all_c = [0.001, 0.01, 0.1, 0.5, 1, 2, 10, 50, 100, 1000]\n",
    "    all_gamma = [0.001, 0.01, 0.1, 0.5, 1, 2, 10, 50, 100, 1000]\n",
    "    \n",
    "    f1_scores = []\n",
    "    print(all_c)\n",
    "    best_model = None\n",
    "    for c, g in tqdm(zip(all_c, all_gamma)):\n",
    "        model = svm.SVC(C=c, gamma = g)\n",
    "        model.fit(x_tr, y_tr)\n",
    "        preds = model.predict(x_val)\n",
    "        cur_f1 = metrics.f1_score(y_val, preds, average = 'micro')\n",
    "        f1_scores.append(cur_f1)\n",
    "        if cur_f1 == max(f1_scores):\n",
    "            best_model = model\n",
    "    print(\"The values of Cs considered are:\", all_c)\n",
    "    print(\"The best f1 score is:\", max(f1_scores))\n",
    "    print(\"The c is set to:\", best_model.get_params()['C'])\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001, 0.01, 0.1, 0.5, 1, 2, 10, 50, 100, 1000]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c57ff22bbf747308e7eec73bfaf2a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-b6a45a129302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfine_tune_linear_SVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fine_tune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlSVM_cs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-218-c5acb2644337>\u001b[0m in \u001b[0;36mfine_tune_linear_SVM\u001b[0;34m(x_tr, y_tr, x_val, y_val, number_of_model, cs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# max_iter is a very large number so there is convergence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcur_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm = fine_tune_linear_SVM(x_tr, y_tr, x_val, y_val, n_fine_tune, lSVM_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
